{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code for Selecting Representative and Uncorrelated Metrics\n",
    "\n",
    "The main objective of the code is to select the most representative and least correlated metrics from various textual datasets. Below are the steps and formulas used in the process:\n",
    "\n",
    "### 1. Filtering Columns by Variance\n",
    "\n",
    "The variance of each column is calculated, and columns with variance less than or equal to a threshold (`variance_threshold`) are removed.\n",
    "\n",
    "### 2. Filtering Columns by Correlation\n",
    "\n",
    "The correlation matrix of the remaining columns is calculated, and columns with a correlation greater than a threshold (`correlation_threshold`) are removed. We place a high emphasis on correlation to avoid the issue of feature importance distribution in methods like Random Forest.\n",
    "\n",
    "### 3. Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is applied to reduce dimensionality and select the most representative variables. PCA transforms the original variables into a new set of uncorrelated variables called principal components.\n",
    "\n",
    "### 4. Variable Selection Based on Loadings\n",
    "\n",
    "Variables with an absolute loading greater than or equal to a threshold (`loading_threshold`) in at least one principal component are selected.\n",
    "\n",
    "### 5. Combining Results\n",
    "\n",
    "Finally, the selected variables from all datasets are combined and the results are saved.\n",
    "\n",
    "### Process Summary\n",
    "\n",
    "1. **Variance Filtering**: Remove columns with low variance.\n",
    "2. **Correlation Filtering**: Remove highly correlated columns. We place a high emphasis on correlation to avoid the issue of feature importance distribution in methods like Random Forest.\n",
    "3. **PCA**: Reduce dimensionality and select variables based on loadings.\n",
    "4. **Combination**: Combine selected variables from all datasets.\n",
    "\n",
    "This process ensures that the selected metrics are representative and non-redundant, thereby improving the quality of subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        raw_data = json.load(file)\n",
    "    # Normalize and flatten JSON structure\n",
    "    normalized_data = pd.json_normalize(raw_data)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron = load_json('datasets/1_metrics/pronvsprompt_short_stories_metrics.json')\n",
    "pron_numerical_cols = pron.select_dtypes(include=['float64', 'int64']).columns\n",
    "slm = load_json('datasets/1_metrics/slm_short_stories_metrics.json')\n",
    "slm_numerical_cols = slm.select_dtypes(include=['float64', 'int64']).columns\n",
    "ttcw = load_json('datasets/1_metrics/ttcw_short_stories_metrics.json')\n",
    "ttcw_numerical_cols = ttcw.select_dtypes(include=['float64', 'int64']).columns\n",
    "hanna = load_json('datasets/1_metrics/hanna_short_stories_metrics.json')\n",
    "hanna_numerical_cols = hanna.select_dtypes(include=['float64', 'int64']).columns\n",
    "confederacy = load_json('datasets/1_metrics/confederacy_short_stories_metrics.json')\n",
    "confederacy_numerical_cols = confederacy.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns eliminated due to low variance: ['coherence_analysis.local_coherence_embeddings', 'coherence_analysis.entity_coherence', 'coherence_analysis.overall_coherence', 'coherence_analysis.coherence_values.2', 'coherence_analysis.coherence_values.3', 'coherence_analysis.coherence_values.4', 'coherence_analysis.coherence_values.5', 'coherence_analysis.coherence_values.6', 'coherence_analysis.coherence_values.7', 'coherence_analysis.coherence_values.8', 'coherence_analysis.coherence_values.9', 'coherence_analysis.coherence_values.10', 'originality_analysis.semantic_distance', 'stylistic_analysis.linguistic_metrics.lexical_diversity.TTR', 'stylistic_analysis.linguistic_metrics.lexical_diversity.log_TTR', 'stylistic_analysis.linguistic_metrics.average_subordination_depth', 'stylistic_analysis.rhetorical_devices.counts.onomatopoeia', 'stylistic_analysis.rhetorical_devices.counts.epiphora', 'stylistic_analysis.rhetorical_devices.counts.paronomasia', 'stylistic_analysis.semantic_density.cosine_similarity', 'stylistic_analysis.semantic_density.entropy', 'stylistic_analysis.sentence_rhythm.coefficient_of_variation', 'sentiment_analysis.average_entropy', 'sentiment_analysis.average_max_confidence', 'sentiment_analysis.average_valence_intensity', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.sentiment_trend', 'sentiment_analysis.temporal_dynamics', 'sentiment_analysis.emotional_complexity', 'sentiment_analysis.emotional_volatility', 'sentiment_analysis.emotional_persistence', 'sentiment_analysis.emotional_oscillation', 'thematic_analysis.inter_theme_similarity', 'thematic_analysis.graph_modularity']\n",
      "Columns removed due to high correlation: ['sentiment_analysis.sentiment_volatility', 'stylistic_analysis.sentence_rhythm.average_change', 'readability_metrics.difficult_words', 'readability_metrics.smog_index', 'readability_metrics.automated_readability_index', 'stylistic_analysis.sentence_rhythm.average_sentence_length', 'readability_metrics.flesch_kincaid_grade', 'stylistic_analysis.linguistic_metrics.sentence_complexity_index', 'readability_metrics.gunning_fog']\n",
      "Columns with rank 0-1 that were maintained: ['sentiment_analysis.variance_sentiment', 'thematic_analysis.entropy_score', 'thematic_analysis.graph_density', 'stylistic_analysis.rhetorical_devices.counts.allegory']\n",
      "Number of components needed to explain 95.0% of variance: 25\n",
      "Archivo guardado: outputs/metric_correlations/representative_pron.csv\n",
      "Columns eliminated due to low variance: ['coherence_analysis.local_coherence_embeddings', 'coherence_analysis.entity_coherence', 'coherence_analysis.overall_coherence', 'coherence_analysis.coherence_values.2', 'coherence_analysis.coherence_values.3', 'coherence_analysis.coherence_values.4', 'coherence_analysis.coherence_values.5', 'coherence_analysis.coherence_values.6', 'coherence_analysis.coherence_values.7', 'coherence_analysis.coherence_values.8', 'coherence_analysis.coherence_values.9', 'coherence_analysis.coherence_values.10', 'originality_analysis.semantic_distance', 'stylistic_analysis.linguistic_metrics.lexical_diversity.TTR', 'stylistic_analysis.linguistic_metrics.lexical_diversity.log_TTR', 'stylistic_analysis.semantic_density.cosine_similarity', 'stylistic_analysis.sentence_rhythm.coefficient_of_variation', 'sentiment_analysis.average_entropy', 'sentiment_analysis.average_max_confidence', 'sentiment_analysis.average_valence_intensity', 'sentiment_analysis.emotional_richness', 'sentiment_analysis.temporal_dynamics', 'sentiment_analysis.emotional_complexity', 'sentiment_analysis.emotional_oscillation', 'thematic_analysis.graph_modularity', 'stylistic_analysis.rhetorical_devices.counts.similes', 'stylistic_analysis.rhetorical_devices.counts.personification', 'stylistic_analysis.rhetorical_devices.counts.oxymoron', 'stylistic_analysis.rhetorical_devices.counts.synesthesia', 'stylistic_analysis.rhetorical_devices.counts.anaphora', 'stylistic_analysis.rhetorical_devices.counts.onomatopoeia', 'stylistic_analysis.rhetorical_devices.counts.paradox', 'stylistic_analysis.rhetorical_devices.counts.rhetorical_questions', 'stylistic_analysis.rhetorical_devices.counts.euphony', 'stylistic_analysis.rhetorical_devices.counts.sarcasm', 'stylistic_analysis.rhetorical_devices.counts.epiphora', 'stylistic_analysis.rhetorical_devices.counts.paronomasia']\n",
      "Columns removed due to high correlation: ['stylistic_analysis.sentence_rhythm.average_change', 'stylistic_analysis.linguistic_metrics.average_subordination_depth', 'readability_metrics.automated_readability_index', 'stylistic_analysis.sentence_rhythm.average_sentence_length', 'readability_metrics.flesch_kincaid_grade', 'stylistic_analysis.rhetorical_devices.variety', 'stylistic_analysis.linguistic_metrics.num_subordinate_clauses', 'readability_metrics.gunning_fog', 'readability_metrics.linsear_write_formula', 'stylistic_analysis.semantic_density.entropy']\n",
      "Columns with rank 0-1 that were maintained: ['sentiment_analysis.variance_sentiment', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.emotional_volatility', 'sentiment_analysis.emotional_persistence', 'thematic_analysis.entropy_score', 'thematic_analysis.inter_theme_similarity', 'thematic_analysis.graph_density', 'stylistic_analysis.rhetorical_devices.counts.hyperbole', 'stylistic_analysis.rhetorical_devices.counts.allusions', 'stylistic_analysis.rhetorical_devices.counts.symbolism']\n",
      "Number of components needed to explain 95.0% of variance: 14\n",
      "Archivo guardado: outputs/metric_correlations/representative_slm.csv\n",
      "Columns eliminated due to low variance: ['coherence_analysis.local_coherence_embeddings', 'coherence_analysis.entity_coherence', 'coherence_analysis.overall_coherence', 'coherence_analysis.coherence_values.2', 'coherence_analysis.coherence_values.3', 'coherence_analysis.coherence_values.4', 'coherence_analysis.coherence_values.5', 'coherence_analysis.coherence_values.6', 'coherence_analysis.coherence_values.7', 'coherence_analysis.coherence_values.8', 'coherence_analysis.coherence_values.9', 'coherence_analysis.coherence_values.10', 'originality_analysis.semantic_distance', 'stylistic_analysis.linguistic_metrics.lexical_diversity.TTR', 'stylistic_analysis.linguistic_metrics.lexical_diversity.log_TTR', 'stylistic_analysis.linguistic_metrics.average_tree_depth', 'stylistic_analysis.linguistic_metrics.average_subordination_depth', 'stylistic_analysis.semantic_density.cosine_similarity', 'stylistic_analysis.semantic_density.entropy', 'stylistic_analysis.sentence_rhythm.coefficient_of_variation', 'sentiment_analysis.average_entropy', 'sentiment_analysis.average_max_confidence', 'sentiment_analysis.average_valence_intensity', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.sentiment_trend', 'sentiment_analysis.temporal_dynamics', 'sentiment_analysis.emotional_complexity', 'sentiment_analysis.emotional_volatility', 'sentiment_analysis.emotional_persistence', 'sentiment_analysis.emotional_oscillation', 'thematic_analysis.entropy_score', 'thematic_analysis.inter_theme_similarity', 'thematic_analysis.graph_density', 'thematic_analysis.graph_modularity', 'stylistic_analysis.rhetorical_devices.counts.allegory']\n",
      "Columns removed due to high correlation: ['sentiment_analysis.sentiment_volatility', 'readability_metrics.text_standard', 'stylistic_analysis.sentence_rhythm.average_change', 'readability_metrics.dale_chall_readability_score', 'readability_metrics.smog_index', 'readability_metrics.difficult_words', 'stylistic_analysis.linguistic_metrics.sentence_complexity_index', 'readability_metrics.coleman_liau_index', 'readability_metrics.automated_readability_index', 'stylistic_analysis.sentence_rhythm.average_sentence_length', 'readability_metrics.flesch_kincaid_grade', 'stylistic_analysis.rhetorical_devices.total_count', 'stylistic_analysis.sentence_rhythm.std_dev_sentence_length', 'stylistic_analysis.linguistic_metrics.num_subordinate_clauses', 'readability_metrics.gunning_fog']\n",
      "Columns with rank 0-1 that were maintained: ['stylistic_analysis.rhetorical_devices.counts.synesthesia', 'stylistic_analysis.rhetorical_devices.counts.euphony', 'stylistic_analysis.rhetorical_devices.counts.sarcasm', 'stylistic_analysis.rhetorical_devices.counts.epiphora', 'stylistic_analysis.rhetorical_devices.counts.paronomasia', 'sentiment_analysis.variance_sentiment']\n",
      "Number of components needed to explain 95.0% of variance: 9\n",
      "Archivo guardado: outputs/metric_correlations/representative_ttcw.csv\n",
      "Columns eliminated due to low variance: ['coherence_analysis.local_coherence_embeddings', 'coherence_analysis.entity_coherence', 'coherence_analysis.overall_coherence', 'coherence_analysis.coherence_values.2', 'coherence_analysis.coherence_values.3', 'coherence_analysis.coherence_values.4', 'coherence_analysis.coherence_values.5', 'coherence_analysis.coherence_values.6', 'coherence_analysis.coherence_values.7', 'coherence_analysis.coherence_values.8', 'coherence_analysis.coherence_values.9', 'coherence_analysis.coherence_values.10', 'originality_analysis.semantic_distance', 'stylistic_analysis.linguistic_metrics.lexical_diversity.TTR', 'stylistic_analysis.linguistic_metrics.lexical_diversity.log_TTR', 'stylistic_analysis.linguistic_metrics.average_subordination_depth', 'stylistic_analysis.rhetorical_devices.counts.euphony', 'stylistic_analysis.rhetorical_devices.counts.paronomasia', 'stylistic_analysis.semantic_density.cosine_similarity', 'stylistic_analysis.sentence_rhythm.coefficient_of_variation', 'sentiment_analysis.average_entropy', 'sentiment_analysis.average_max_confidence', 'sentiment_analysis.average_valence_intensity', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.sentiment_trend', 'sentiment_analysis.temporal_dynamics', 'sentiment_analysis.emotional_complexity', 'sentiment_analysis.emotional_oscillation', 'thematic_analysis.inter_theme_similarity', 'thematic_analysis.graph_density', 'thematic_analysis.graph_modularity', 'stylistic_analysis.rhetorical_devices.counts.allegory']\n",
      "Columns removed due to high correlation: ['stylistic_analysis.sentence_rhythm.average_change', 'readability_metrics.automated_readability_index', 'stylistic_analysis.sentence_rhythm.average_sentence_length', 'readability_metrics.flesch_kincaid_grade', 'stylistic_analysis.rhetorical_devices.variety', 'stylistic_analysis.linguistic_metrics.num_subordinate_clauses', 'readability_metrics.gunning_fog', 'stylistic_analysis.semantic_density.entropy']\n",
      "Columns with rank 0-1 that were maintained: ['sentiment_analysis.variance_sentiment', 'sentiment_analysis.emotional_volatility', 'sentiment_analysis.emotional_persistence']\n",
      "Number of components needed to explain 95.0% of variance: 16\n",
      "Archivo guardado: outputs/metric_correlations/representative_hanna.csv\n",
      "Columns eliminated due to low variance: ['coherence_analysis.local_coherence_embeddings', 'coherence_analysis.entity_coherence', 'coherence_analysis.overall_coherence', 'coherence_analysis.coherence_values.2', 'coherence_analysis.coherence_values.3', 'coherence_analysis.coherence_values.4', 'coherence_analysis.coherence_values.5', 'coherence_analysis.coherence_values.6', 'coherence_analysis.coherence_values.7', 'coherence_analysis.coherence_values.8', 'coherence_analysis.coherence_values.9', 'coherence_analysis.coherence_values.10', 'originality_analysis.semantic_distance', 'stylistic_analysis.linguistic_metrics.lexical_diversity.TTR', 'stylistic_analysis.linguistic_metrics.lexical_diversity.log_TTR', 'stylistic_analysis.linguistic_metrics.average_tree_depth', 'stylistic_analysis.linguistic_metrics.average_subordination_depth', 'stylistic_analysis.rhetorical_devices.counts.synesthesia', 'stylistic_analysis.rhetorical_devices.counts.paradox', 'stylistic_analysis.rhetorical_devices.counts.epiphora', 'stylistic_analysis.semantic_density.cosine_similarity', 'stylistic_analysis.sentence_rhythm.coefficient_of_variation', 'sentiment_analysis.average_entropy', 'sentiment_analysis.average_max_confidence', 'sentiment_analysis.average_valence_intensity', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.sentiment_trend', 'sentiment_analysis.temporal_dynamics', 'sentiment_analysis.emotional_complexity', 'sentiment_analysis.emotional_volatility', 'sentiment_analysis.emotional_persistence', 'sentiment_analysis.emotional_oscillation', 'thematic_analysis.inter_theme_similarity', 'thematic_analysis.graph_modularity', 'stylistic_analysis.rhetorical_devices.counts.allegory']\n",
      "Columns removed due to high correlation: ['stylistic_analysis.sentence_rhythm.average_change', 'readability_metrics.dale_chall_readability_score', 'readability_metrics.smog_index', 'readability_metrics.difficult_words', 'readability_metrics.coleman_liau_index', 'readability_metrics.automated_readability_index', 'stylistic_analysis.sentence_rhythm.average_sentence_length', 'readability_metrics.flesch_kincaid_grade', 'stylistic_analysis.rhetorical_devices.variety', 'stylistic_analysis.linguistic_metrics.num_subordinate_clauses', 'readability_metrics.gunning_fog', 'stylistic_analysis.semantic_density.entropy']\n",
      "Columns with rank 0-1 that were maintained: ['stylistic_analysis.rhetorical_devices.counts.euphony', 'sentiment_analysis.variance_sentiment', 'thematic_analysis.entropy_score', 'thematic_analysis.graph_density']\n",
      "Number of components needed to explain 95.0% of variance: 11\n",
      "Archivo guardado: outputs/metric_correlations/representative_confederacy.csv\n",
      "Columns present in at least one dataset: {'stylistic_analysis.rhetorical_devices.counts.synesthesia', 'sentiment_analysis.sentiment_distribution_negative', 'sentiment_analysis.sentiment_trend', 'stylistic_analysis.linguistic_metrics.average_tree_depth', 'thematic_analysis.graph_density', 'sentiment_analysis.sentiment_distribution_positive', 'sentiment_analysis.emotional_persistence', 'stylistic_analysis.linguistic_metrics.sentence_complexity_index', 'sentiment_analysis.average_sentiment', 'readability_metrics.text_standard', 'stylistic_analysis.rhetorical_devices.counts.euphony', 'stylistic_analysis.rhetorical_devices.counts.hyperbole', 'stylistic_analysis.rhetorical_devices.counts.epiphora', 'sentiment_analysis.variance_sentiment', 'stylistic_analysis.linguistic_metrics.average_sentence_length', 'sentiment_analysis.sentiment_volatility', 'stylistic_analysis.rhetorical_devices.counts.symbolism', 'stylistic_analysis.linguistic_metrics.lexical_diversity.MTLD', 'thematic_analysis.entropy_score', 'story_idx', 'sentiment_analysis.emotional_richness', 'stylistic_analysis.rhetorical_devices.total_count', 'stylistic_analysis.rhetorical_devices.counts.paronomasia', 'stylistic_analysis.sentence_rhythm.std_dev_sentence_length', 'stylistic_analysis.rhetorical_devices.counts.enumerations', 'thematic_analysis.inter_theme_similarity', 'stylistic_analysis.linguistic_metrics.max_subordination_depth', 'readability_metrics.smog_index', 'stylistic_analysis.rhetorical_devices.counts.allegory', 'stylistic_analysis.linguistic_metrics.dependency_variety', 'stylistic_analysis.rhetorical_devices.counts.allusions', 'stylistic_analysis.rhetorical_devices.counts.sarcasm', 'stylistic_analysis.rhetorical_devices.variety', 'coherence_analysis.best_num_topics', 'sentiment_analysis.emotional_volatility', 'readability_metrics.linsear_write_formula'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_folder = 'outputs/metric_correlations'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "datasets = {\n",
    "    'representative_pron.csv': pron[pron_numerical_cols],\n",
    "    'representative_slm.csv': slm[slm_numerical_cols],\n",
    "    'representative_ttcw.csv': ttcw[ttcw_numerical_cols],\n",
    "    'representative_hanna.csv': hanna[hanna_numerical_cols],\n",
    "    'representative_confederacy.csv': confederacy[confederacy_numerical_cols]\n",
    "\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# function to select the most representative metrics\n",
    "def select_representative_variables(df, variance_threshold=0.05, correlation_threshold=0.8, explained_variance_target=0.95, loading_threshold=0.5, dataset_name=\"dataset\"):\n",
    "    # Filter columns that do not start with 'sentiment_analysis.emotion_transitions_map'\n",
    "    df = df[df.columns[~df.columns.str.startswith(\"sentiment_analysis.emotion_transitions_map\")]]\n",
    "    \n",
    "    # Calculate the variance of each column\n",
    "    variance = df.var()\n",
    "    low_variance_columns = variance[variance <= variance_threshold].index.tolist()\n",
    "    high_variance_columns = variance[variance > variance_threshold].index\n",
    "\n",
    "    # Identify variables with reduced range between 0 and 1\n",
    "    normalized_columns = [col for col in high_variance_columns \n",
    "                          if df[col].min() >= 0 and df[col].max() <= 1]\n",
    "\n",
    "    # Exclude variables of reduced range from filtering\n",
    "    final_high_variance_columns = [col for col in high_variance_columns if col not in normalized_columns]\n",
    "\n",
    "    # Save data from columns deleted due to low variance\n",
    "    output_folder = 'outputs/metric_correlations/reports'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    df[low_variance_columns].to_csv(f'{output_folder}/{dataset_name}_low_variance_columns.csv', index=False)\n",
    "\n",
    "    # Filter columns with high variance\n",
    "    filtered_df = df[final_high_variance_columns].copy()\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "\n",
    "    correlation_matrix = filtered_df.corr().abs()\n",
    "\n",
    "    # Identify columns with high correlation\n",
    "    to_drop = set()\n",
    "    correlation_report = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if correlation_matrix.iloc[i, j] > correlation_threshold:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                to_drop.add(colname)\n",
    "                correlation_report.append((correlation_matrix.columns[j], colname, correlation_matrix.iloc[i, j]))\n",
    "\n",
    "    # Save data from columns removed due to high correlation\n",
    "    df[list(to_drop)].to_csv(f'{output_folder}/{dataset_name}_high_correlation_columns.csv', index=False)\n",
    "\n",
    "    # Save correlation report\n",
    "    correlation_df = pd.DataFrame(correlation_report, columns=['Variable 1', 'Variable 2', 'Correlation'])\n",
    "    correlation_df.to_csv(f'{output_folder}/{dataset_name}_correlation_report.csv', index=False)\n",
    "\n",
    "    # Save variance report\n",
    "    variance_report_df = pd.DataFrame(variance, columns=['Variance'])\n",
    "    variance_report_df.to_csv(f'{output_folder}/{dataset_name}_variance_report.csv')\n",
    "\n",
    "    print(f\"Columns eliminated due to low variance: {low_variance_columns}\")\n",
    "    print(f\"Columns removed due to high correlation: {list(to_drop)}\")\n",
    "    print(f\"Columns with rank 0-1 that were maintained: {normalized_columns}\")\n",
    "\n",
    "    # Initial column selection after filtering high correlation\n",
    "    remaining_cols = [col for col in filtered_df.columns if col not in to_drop]\n",
    "    filtered_df = filtered_df[remaining_cols]\n",
    "\n",
    "    # --- Start of the integration of PCA ---\n",
    "    # Standardise data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(filtered_df.dropna(axis=1, how='any'))  \n",
    "    # Note: NaN columns are removed for PCA; adjust as necessary.\n",
    "\n",
    "    # Apply PCA initially to determine the number of components required.\n",
    "    pca_full = PCA()\n",
    "    pca_full.fit(scaled_data)\n",
    "    explained_variance = pca_full.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    # Determine the number of components to reach the explained variance threshold\n",
    "    num_components = np.argmax(cumulative_variance >= explained_variance_target) + 1\n",
    "    print(f\"Number of components needed to explain {explained_variance_target*100}% of variance: {num_components}\")\n",
    "\n",
    "    # Apply PCA with the optimal number of components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "    # Obtain loadings for each variable in each principal component.\n",
    "    loadings = pd.DataFrame(pca.components_.T, \n",
    "                            index=filtered_df.dropna(axis=1, how='any').columns,\n",
    "                            columns=[f'PC{i+1}' for i in range(num_components)])\n",
    "    loadings.to_csv(f'{output_folder}/{dataset_name}_pca_loadings.csv')\n",
    "\n",
    "    # Select variables that have high loadings in at least one component\n",
    "    selected_vars = set()\n",
    "    for pc in loadings.columns:\n",
    "        high_loading_vars = loadings.index[loadings[pc].abs() >= loading_threshold].tolist()\n",
    "        selected_vars.update(high_loading_vars)\n",
    "\n",
    "    # --- End of PCA integration --- --- End of PCA integration\n",
    "\n",
    "    # Combine selected variables with previously identified normalised ones\n",
    "    final_selected_columns = list(selected_vars) + normalized_columns\n",
    "\n",
    "    # Make sure that the selected columns exist in the original dataframe.\n",
    "    final_selected_columns = [col for col in final_selected_columns if col in df.columns]\n",
    "\n",
    "    # Return the final dataframe with the selected variables\n",
    "    return df[final_selected_columns]\n",
    "\n",
    "# Process each file with the new function included in PCA\n",
    "selected_columns_sets = []\n",
    "for output_filename, df in datasets.items():\n",
    "    representative_df = select_representative_variables(df, dataset_name=output_filename.replace('.csv', ''))\n",
    "    selected_columns_sets.append(set(representative_df.columns))\n",
    "    representative_df.to_csv(f'{output_folder}/{output_filename}', index=False)\n",
    "    print(f\"Archivo guardado: {output_folder}/{output_filename}\")\n",
    "\n",
    "# Rest of the code to join and save selected columns...\n",
    "all_selected_columns = set().union(*selected_columns_sets)\n",
    "print(f\"Columns present in at least one dataset: {all_selected_columns}\")\n",
    "\n",
    "with open(f'{output_folder}/all_selected_columns.txt', 'w') as file:\n",
    "    file.write(\"\\n\".join(all_selected_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
