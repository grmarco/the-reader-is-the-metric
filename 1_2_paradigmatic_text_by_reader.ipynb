{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Paradigmatic Text Profiles for Readers\n",
    "\n",
    "To characterize each reader $r_j$’s overall preferences within a single dataset, we aggregate the corpus features weighted by the reader’s preference intensities. Specifically, for reader $r_j$, we define a vector\n",
    "$$\n",
    "\\mathbf{x}_j^{*} \n",
    "\\;=\\;\n",
    "\\frac{\\sum_{i=1}^t\\,\\rho_j(x_i)\\,\\mathbf{x}_i}\n",
    "     {\\sum_{i=1}^t\\,\\rho_j(x_i)},\n",
    "$$\n",
    "where $\\rho_j(x_i)$ indicates how strongly $r_j$ prefers text $x_i$. Texts that $r_j$ highly favors contribute more to $\\mathbf{x}_j^{*}$, whereas texts receiving negligible scores have limited impact. The resulting paradigmatic vector $\\mathbf{x}_j^{*}$ can be viewed as an  “ideal text” representation for the given reader, distilled from the corpus under study. Plotting these vectors (e.g., via PCA) reveals clusters of readers who place emphasis \n",
    "on similar sets of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from config import selected_features\n",
    "\n",
    "def get_nested_value(d, key):\n",
    "    \"\"\"Extracts the value of a nested dictionary given a key in the format 'level1.level2...'.\"\"\"\n",
    "    keys = key.split('.')\n",
    "    for k in keys:\n",
    "        if isinstance(d, dict):\n",
    "            d = d.get(k, None)\n",
    "        else:\n",
    "            return None\n",
    "    return d\n",
    "\n",
    "def process_dataset(prefix, metrics_filepath, rankings_filepath):\n",
    "    # Load and transform the metrics JSON\n",
    "    with open(metrics_filepath, 'r') as f:\n",
    "        metrics_data = json.load(f)\n",
    "\n",
    "    metrics_flat = []\n",
    "    for row in metrics_data:\n",
    "        flat_row = {}\n",
    "        for col in selected_features:\n",
    "            flat_row[col] = get_nested_value(row, col)\n",
    "        flat_row['story_id'] = row.get('story_id')\n",
    "        metrics_flat.append(flat_row)\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_flat)\n",
    "\n",
    "    df_rankings = pd.read_csv(rankings_filepath)\n",
    "\n",
    "    # Merge of the two sources using story_id\n",
    "    df_merged = df_rankings.merge(df_metrics, on='story_id', how='inner')\n",
    "\n",
    "    # Convert feature columns to numeric\n",
    "    for col in selected_features:\n",
    "        df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "    # Multiplicar cada feature por ranking_value_norm\n",
    "    for col in selected_features:\n",
    "        df_merged[col] = df_merged[col] * df_merged['ranking_value_norm']\n",
    "\n",
    "    # Function to calculate weighted average per user\n",
    "    def weighted_average(group):\n",
    "        weight_sum = group['ranking_value_norm'].sum()\n",
    "        result = {}\n",
    "        for col in selected_features:\n",
    "            result[col] = group[col].sum() / weight_sum if weight_sum != 0 else None\n",
    "        return pd.Series(result)\n",
    "\n",
    "    df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n",
    "    # Add dataset identifier column\n",
    "    df_weighted['dataset'] = prefix\n",
    "    return df_weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: confederacy\n",
      "Processing dataset: ttcw\n",
      "Processing dataset: slm\n",
      "Processing dataset: hanna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_601781/4182291763.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n",
      "/tmp/ipykernel_601781/4182291763.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n",
      "/tmp/ipykernel_601781/4182291763.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: pronvsprompt\n",
      "Resultados guardados en: outputs/paradigmatic_texts_by_user.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_601781/4182291763.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n",
      "/tmp/ipykernel_601781/4182291763.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_weighted = df_merged.groupby('user_id', as_index=False, group_keys=False).apply(weighted_average)\n"
     ]
    }
   ],
   "source": [
    "metrics_dir = 'datasets/1_metrics'\n",
    "rankings_dir = 'datasets/1_2_rankings'\n",
    "\n",
    "# Names are assumed to be prefixed with _short_stories_metrics.json for metrics.\n",
    "# and the same prefix followed by _rankings.csv for rankings.\n",
    "metrics_files = glob.glob(os.path.join(metrics_dir, '*_short_stories_metrics.json'))\n",
    "\n",
    "results = []\n",
    "for metrics_filepath in metrics_files:\n",
    "    # Extract the filename prefix\n",
    "    base_metrics = os.path.basename(metrics_filepath)\n",
    "    prefix = base_metrics.split('_')[0]\n",
    "    # Build the filepath from the CSV in rankings using the same prefix\n",
    "    rankings_filepath = os.path.join(rankings_dir, f'{prefix}_rankings.csv')\n",
    "    if os.path.exists(rankings_filepath):\n",
    "        print(f'Processing dataset: {prefix}')\n",
    "        df_res = process_dataset(prefix, metrics_filepath, rankings_filepath)\n",
    "        results.append(df_res)\n",
    "    else:\n",
    "        print(f'No rankings file was found for the dataset: {prefix}')\n",
    "\n",
    "# Concatenate the results and save as final CSV\n",
    "if results:\n",
    "    df_final = pd.concat(results, ignore_index=True)\n",
    "    output_filepath = 'outputs/paradigmatic_texts_by_user.csv'\n",
    "    df_final.to_csv(output_filepath, index=False)\n",
    "    print(f'Resultados guardados en: {output_filepath}')\n",
    "else:\n",
    "    print('No datasets were processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
