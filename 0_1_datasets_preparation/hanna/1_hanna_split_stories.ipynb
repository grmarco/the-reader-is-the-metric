{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historias únicas guardadas en unique_stories.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('/home/gmarco/workspace/canon_explicability/datasets/hanna/input/original_data/hanna-benchmark-asg-coling/hanna_stories_annotations.csv')\n",
    "\n",
    "# Eliminar duplicados basados en las columnas 'Story ID', 'Model' y 'Story'\n",
    "unique_stories = df.drop_duplicates(subset=['Story ID', 'Model', 'Story'])\n",
    "\n",
    "# Crear una lista de diccionarios con el formato deseado\n",
    "stories_list = []\n",
    "for idx, row in unique_stories.iterrows():\n",
    "    story_dict = {\n",
    "        \"story_idx\": idx,\n",
    "        \"story_id\": f\"{row['Story ID']}_{row['Model']}\",\n",
    "        \"story_name\": row['Prompt'],\n",
    "        \"content\": row['Story']\n",
    "    }\n",
    "    stories_list.append(story_dict)\n",
    "\n",
    "# Guardar las historias en un archivo JSON\n",
    "with open('unique_stories.json', 'w') as json_file:\n",
    "    json.dump(stories_list, json_file, indent=4)\n",
    "\n",
    "print(\"Historias únicas guardadas en unique_stories.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker ID: A03922113RU44GENR8ATX, Textos: 35, Pares esperados: 595\n",
      "Worker ID: A03922113RU44GENR8ATX, Pares generados: 595, Coincide con lo esperado: True\n",
      "Worker ID: A1IZ4NX41GKU4X, Textos: 942, Pares esperados: 443211\n",
      "Worker ID: A1IZ4NX41GKU4X, Pares generados: 443211, Coincide con lo esperado: True\n",
      "Worker ID: A1MJVTR0PCKBWW, Textos: 1, Pares esperados: 0\n",
      "Worker ID: A1MJVTR0PCKBWW, Pares generados: 0, Coincide con lo esperado: True\n",
      "Worker ID: A1SWRO4LMKPCOQ, Textos: 4, Pares esperados: 6\n",
      "Worker ID: A1SWRO4LMKPCOQ, Pares generados: 6, Coincide con lo esperado: True\n",
      "Worker ID: A1V6CP5I0TOSAR, Textos: 98, Pares esperados: 4753\n",
      "Worker ID: A1V6CP5I0TOSAR, Pares generados: 4753, Coincide con lo esperado: True\n",
      "Worker ID: A219VCQZADQ45W, Textos: 4, Pares esperados: 6\n",
      "Worker ID: A219VCQZADQ45W, Pares generados: 6, Coincide con lo esperado: True\n",
      "Worker ID: A23LXQ5ZX2YONR, Textos: 7, Pares esperados: 21\n",
      "Worker ID: A23LXQ5ZX2YONR, Pares generados: 21, Coincide con lo esperado: True\n",
      "Worker ID: A264NN7JBX4UDQ, Textos: 203, Pares esperados: 20503\n",
      "Worker ID: A264NN7JBX4UDQ, Pares generados: 20503, Coincide con lo esperado: True\n",
      "Worker ID: A2LT6KC1X51FVW, Textos: 1, Pares esperados: 0\n",
      "Worker ID: A2LT6KC1X51FVW, Pares generados: 0, Coincide con lo esperado: True\n",
      "Worker ID: A2VE5IV9OD2SK1, Textos: 887, Pares esperados: 392941\n",
      "Worker ID: A2VE5IV9OD2SK1, Pares generados: 392941, Coincide con lo esperado: True\n",
      "Worker ID: A2WNW8A4MOR7T7, Textos: 262, Pares esperados: 34191\n",
      "Worker ID: A2WNW8A4MOR7T7, Pares generados: 34191, Coincide con lo esperado: True\n",
      "Worker ID: A33EE91AZUG1LW, Textos: 5, Pares esperados: 10\n",
      "Worker ID: A33EE91AZUG1LW, Pares generados: 10, Coincide con lo esperado: True\n",
      "Worker ID: A36LOA6VLJU157, Textos: 2, Pares esperados: 1\n",
      "Worker ID: A36LOA6VLJU157, Pares generados: 1, Coincide con lo esperado: True\n",
      "Worker ID: A37WDOIQH6JM6V, Textos: 1, Pares esperados: 0\n",
      "Worker ID: A37WDOIQH6JM6V, Pares generados: 0, Coincide con lo esperado: True\n",
      "Worker ID: A3CFNUD7VR2E1E, Textos: 661, Pares esperados: 218130\n",
      "Worker ID: A3CFNUD7VR2E1E, Pares generados: 218130, Coincide con lo esperado: True\n",
      "Worker ID: A3RHGIMIWFXPJ7, Textos: 1, Pares esperados: 0\n",
      "Worker ID: A3RHGIMIWFXPJ7, Pares generados: 0, Coincide con lo esperado: True\n",
      "Worker ID: A3UDP95JGEX3H1, Textos: 3, Pares esperados: 3\n",
      "Worker ID: A3UDP95JGEX3H1, Pares generados: 3, Coincide con lo esperado: True\n",
      "Worker ID: ABNJZG6Q8TVDQ, Textos: 3, Pares esperados: 3\n",
      "Worker ID: ABNJZG6Q8TVDQ, Pares generados: 3, Coincide con lo esperado: True\n",
      "Worker ID: AE861G0AY5RGT, Textos: 27, Pares esperados: 351\n",
      "Worker ID: AE861G0AY5RGT, Pares generados: 351, Coincide con lo esperado: True\n",
      "Worker ID: AHV4U78TUUDKI, Textos: 9, Pares esperados: 36\n",
      "Worker ID: AHV4U78TUUDKI, Pares generados: 36, Coincide con lo esperado: True\n",
      "Worker ID: AJD3JOWNVDZD1, Textos: 1, Pares esperados: 0\n",
      "Worker ID: AJD3JOWNVDZD1, Pares generados: 0, Coincide con lo esperado: True\n",
      "Worker ID: AYJGQBBK6KXZ7, Textos: 11, Pares esperados: 55\n",
      "Worker ID: AYJGQBBK6KXZ7, Pares generados: 55, Coincide con lo esperado: True\n",
      "                     worker_id preferred_text  other_text  label\n",
      "0        A03922113RU44GENR8ATX        2_Human     8_Human      1\n",
      "1        A03922113RU44GENR8ATX        8_Human     2_Human      0\n",
      "2        A03922113RU44GENR8ATX        2_Human    29_Human      1\n",
      "3        A03922113RU44GENR8ATX       29_Human     2_Human      0\n",
      "4        A03922113RU44GENR8ATX        2_Human    39_Human      1\n",
      "...                        ...            ...         ...    ...\n",
      "2047863          AYJGQBBK6KXZ7     807_Fusion   732_XLNet      0\n",
      "2047864          AYJGQBBK6KXZ7      732_XLNet  999_TD-VAE      1\n",
      "2047865          AYJGQBBK6KXZ7     999_TD-VAE   732_XLNet      0\n",
      "2047866          AYJGQBBK6KXZ7     999_TD-VAE  807_Fusion      1\n",
      "2047867          AYJGQBBK6KXZ7     807_Fusion  999_TD-VAE      0\n",
      "\n",
      "[2047868 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = '/home/gmarco/workspace/canon_explicability/datasets/hanna/input/hanna_stories_annotations.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Crear la columna 'story_id' combinando 'Story ID' y 'Model'\n",
    "df['story_id'] = df['Story ID'].astype(str) + '_' + df['Model']\n",
    "\n",
    "# Definir las columnas de puntuación a considerar\n",
    "score_columns = ['Relevance', 'Coherence', 'Empathy', 'Surprise', 'Engagement', 'Complexity']\n",
    "\n",
    "# Inicializar una lista para almacenar las comparaciones por pares\n",
    "pairwise_data = []\n",
    "\n",
    "# Generar comparaciones por pares considerando la suma de las puntuaciones\n",
    "for worker_id, group in df.groupby('Worker ID'):\n",
    "    num_texts = len(group)\n",
    "    expected_pairs = math.comb(num_texts, 2)\n",
    "    print(f\"Worker ID: {worker_id}, Textos: {num_texts}, Pares esperados: {expected_pairs}\")\n",
    "    pairs_count = 0\n",
    "    for (idx1, text1), (idx2, text2) in combinations(group.iterrows(), 2):\n",
    "        # Calcular la suma de puntuación para cada historia\n",
    "        score_text1 = text1[score_columns].sum()\n",
    "        score_text2 = text2[score_columns].sum()\n",
    "        \n",
    "        # Comparar las puntuaciones y registrar la preferencia\n",
    "        if score_text1 > score_text2:\n",
    "            pairwise_data.append({\n",
    "                'worker_id': worker_id,\n",
    "                'preferred_text': text1['story_id'],\n",
    "                'other_text': text2['story_id'],\n",
    "                'label': 1\n",
    "            })\n",
    "            pairwise_data.append({\n",
    "                'worker_id': worker_id,\n",
    "                'preferred_text': text2['story_id'],\n",
    "                'other_text': text1['story_id'],\n",
    "                'label': 0\n",
    "            })\n",
    "        elif score_text1 < score_text2:\n",
    "            pairwise_data.append({\n",
    "                'worker_id': worker_id,\n",
    "                'preferred_text': text2['story_id'],\n",
    "                'other_text': text1['story_id'],\n",
    "                'label': 1\n",
    "            })\n",
    "            pairwise_data.append({\n",
    "                'worker_id': worker_id,\n",
    "                'preferred_text': text1['story_id'],\n",
    "                'other_text': text2['story_id'],\n",
    "                'label': 0\n",
    "            })\n",
    "        \n",
    "        pairs_count += 1\n",
    "    \n",
    "    # Comprobar si se generaron los pares esperados\n",
    "    print(f\"Worker ID: {worker_id}, Pares generados: {pairs_count}, Coincide con lo esperado: {pairs_count == expected_pairs}\")\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "pairwise_df = pd.DataFrame(pairwise_data)\n",
    "\n",
    "# Convertir columnas a minúsculas\n",
    "pairwise_df.columns = [col.lower() for col in pairwise_df.columns]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(pairwise_df)\n",
    "\n",
    "# Exportar a CSV si es necesario\n",
    "pairwise_df.to_csv('/home/gmarco/workspace/canon_explicability/datasets/hanna/output/pairwise_comparison_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>preferred_text</th>\n",
       "      <th>other_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A03922113RU44GENR8ATX</td>\n",
       "      <td>2_Human</td>\n",
       "      <td>8_Human</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A03922113RU44GENR8ATX</td>\n",
       "      <td>8_Human</td>\n",
       "      <td>2_Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A03922113RU44GENR8ATX</td>\n",
       "      <td>2_Human</td>\n",
       "      <td>29_Human</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A03922113RU44GENR8ATX</td>\n",
       "      <td>29_Human</td>\n",
       "      <td>2_Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A03922113RU44GENR8ATX</td>\n",
       "      <td>2_Human</td>\n",
       "      <td>39_Human</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047863</th>\n",
       "      <td>AYJGQBBK6KXZ7</td>\n",
       "      <td>807_Fusion</td>\n",
       "      <td>732_XLNet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047864</th>\n",
       "      <td>AYJGQBBK6KXZ7</td>\n",
       "      <td>732_XLNet</td>\n",
       "      <td>999_TD-VAE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047865</th>\n",
       "      <td>AYJGQBBK6KXZ7</td>\n",
       "      <td>999_TD-VAE</td>\n",
       "      <td>732_XLNet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047866</th>\n",
       "      <td>AYJGQBBK6KXZ7</td>\n",
       "      <td>999_TD-VAE</td>\n",
       "      <td>807_Fusion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047867</th>\n",
       "      <td>AYJGQBBK6KXZ7</td>\n",
       "      <td>807_Fusion</td>\n",
       "      <td>999_TD-VAE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2047868 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     worker_id preferred_text  other_text  label\n",
       "0        A03922113RU44GENR8ATX        2_Human     8_Human      1\n",
       "1        A03922113RU44GENR8ATX        8_Human     2_Human      0\n",
       "2        A03922113RU44GENR8ATX        2_Human    29_Human      1\n",
       "3        A03922113RU44GENR8ATX       29_Human     2_Human      0\n",
       "4        A03922113RU44GENR8ATX        2_Human    39_Human      1\n",
       "...                        ...            ...         ...    ...\n",
       "2047863          AYJGQBBK6KXZ7     807_Fusion   732_XLNet      0\n",
       "2047864          AYJGQBBK6KXZ7      732_XLNet  999_TD-VAE      1\n",
       "2047865          AYJGQBBK6KXZ7     999_TD-VAE   732_XLNet      0\n",
       "2047866          AYJGQBBK6KXZ7     999_TD-VAE  807_Fusion      1\n",
       "2047867          AYJGQBBK6KXZ7     807_Fusion  999_TD-VAE      0\n",
       "\n",
       "[2047868 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos filtrados guardados en /home/gmarco/workspace/canon_explicability/datasets_final/1_pairwise/hanna_pairs_balanced.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Supongamos que tu DataFrame se llama df\n",
    "# Cargar el DataFrame desde un archivo CSV (si es necesario)\n",
    "# df = pd.read_csv('path/to/your/csvfile.csv')\n",
    "\n",
    "# Contar el número de comparaciones por cada worker_id\n",
    "\n",
    "pairwise_df.rename(columns={'worker_id': 'user_id'}, inplace=True)\n",
    "\n",
    "comparisons_count = pairwise_df['user_id'].value_counts()\n",
    "\n",
    "# Filtrar los worker_id que tengan más de 100 comparaciones\n",
    "filtered_worker_ids = comparisons_count[comparisons_count > 50].index\n",
    "\n",
    "# Filtrar el DataFrame original para incluir solo los worker_id con más de 100 comparaciones\n",
    "filtered_df = pairwise_df[pairwise_df['user_id'].isin(filtered_worker_ids)]\n",
    "\n",
    "\n",
    "# Convertir el DataFrame filtrado a una lista de diccionarios\n",
    "filtered_data = filtered_df.to_dict(orient='records')\n",
    "\n",
    "# Guardar los datos filtrados en un archivo JSON\n",
    "output_path = '/home/gmarco/workspace/canon_explicability/datasets_final/1_pairwise/hanna_pairs_balanced.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(filtered_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Datos filtrados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "A1IZ4NX41GKU4X           813814\n",
       "A2VE5IV9OD2SK1           716764\n",
       "A3CFNUD7VR2E1E           408842\n",
       "A2WNW8A4MOR7T7            61210\n",
       "A264NN7JBX4UDQ            36112\n",
       "A1V6CP5I0TOSAR             9080\n",
       "A03922113RU44GENR8ATX      1116\n",
       "AE861G0AY5RGT               668\n",
       "AYJGQBBK6KXZ7               102\n",
       "AHV4U78TUUDKI                66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
